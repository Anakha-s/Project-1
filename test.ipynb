{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNXw+QQzvYFMvqpXZd3WuJl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anakha-s/Project-1/blob/main/test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "nWvNjn-pJ4Ts",
        "outputId": "ed3a7c45-c776-44e8-b487-6401f1202aaf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "## EDA Pkgs\n",
        "import pandas as pd\n",
        "#Data Viz Pkg\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from textblob import TextBlob\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('stopwords')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from collections import defaultdict\n",
        "from nltk.corpus import wordnet as wn\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn import model_selection, naive_bayes, svm\n",
        "from sklearn.metrics import accuracy_score\n",
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "df = pd.read_csv(\"covid19_tweets.csv\")\n",
        "# Preview\n",
        "df.head()"
      ],
      "metadata": {
        "id": "8NvN6kbTKAxm",
        "outputId": "05d31416-8b26-4781-d0a8-70f1c46456d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b40aefb4-fab6-4da6-beb5-6150215bbd6c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_name</th>\n",
              "      <th>user_location</th>\n",
              "      <th>user_description</th>\n",
              "      <th>user_created</th>\n",
              "      <th>user_followers</th>\n",
              "      <th>user_friends</th>\n",
              "      <th>user_favourites</th>\n",
              "      <th>user_verified</th>\n",
              "      <th>date</th>\n",
              "      <th>text</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>source</th>\n",
              "      <th>is_retweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>·èâ·é•‚òª’¨ÍÇÖœÆ</td>\n",
              "      <td>astroworld</td>\n",
              "      <td>wednesday addams as a disney princess keepin i...</td>\n",
              "      <td>2017-05-26 05:46:42</td>\n",
              "      <td>624</td>\n",
              "      <td>950</td>\n",
              "      <td>18775</td>\n",
              "      <td>False</td>\n",
              "      <td>2020-07-25 12:27:21</td>\n",
              "      <td>If I smelled the scent of hand sanitizers toda...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Tom Basile üá∫üá∏</td>\n",
              "      <td>New York, NY</td>\n",
              "      <td>Husband, Father, Columnist &amp; Commentator. Auth...</td>\n",
              "      <td>2009-04-16 20:06:23</td>\n",
              "      <td>2253</td>\n",
              "      <td>1677</td>\n",
              "      <td>24</td>\n",
              "      <td>True</td>\n",
              "      <td>2020-07-25 12:27:17</td>\n",
              "      <td>Hey @Yankees @YankeesPR and @MLB - wouldn't it...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Twitter for Android</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Time4fisticuffs</td>\n",
              "      <td>Pewee Valley, KY</td>\n",
              "      <td>#Christian #Catholic #Conservative #Reagan #Re...</td>\n",
              "      <td>2009-02-28 18:57:41</td>\n",
              "      <td>9275</td>\n",
              "      <td>9525</td>\n",
              "      <td>7254</td>\n",
              "      <td>False</td>\n",
              "      <td>2020-07-25 12:27:14</td>\n",
              "      <td>@diane3443 @wdunlap @realDonaldTrump Trump nev...</td>\n",
              "      <td>['COVID19']</td>\n",
              "      <td>Twitter for Android</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ethel mertz</td>\n",
              "      <td>Stuck in the Middle</td>\n",
              "      <td>#Browns #Indians #ClevelandProud #[]_[] #Cavs ...</td>\n",
              "      <td>2019-03-07 01:45:06</td>\n",
              "      <td>197</td>\n",
              "      <td>987</td>\n",
              "      <td>1488</td>\n",
              "      <td>False</td>\n",
              "      <td>2020-07-25 12:27:10</td>\n",
              "      <td>@brookbanktv The one gift #COVID19 has give me...</td>\n",
              "      <td>['COVID19']</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>DIPR-J&amp;K</td>\n",
              "      <td>Jammu and Kashmir</td>\n",
              "      <td>üñäÔ∏èOfficial Twitter handle of Department of Inf...</td>\n",
              "      <td>2017-02-12 06:45:15</td>\n",
              "      <td>101009</td>\n",
              "      <td>168</td>\n",
              "      <td>101</td>\n",
              "      <td>False</td>\n",
              "      <td>2020-07-25 12:27:08</td>\n",
              "      <td>25 July : Media Bulletin on Novel #CoronaVirus...</td>\n",
              "      <td>['CoronaVirusUpdates', 'COVID19']</td>\n",
              "      <td>Twitter for Android</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b40aefb4-fab6-4da6-beb5-6150215bbd6c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b40aefb4-fab6-4da6-beb5-6150215bbd6c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b40aefb4-fab6-4da6-beb5-6150215bbd6c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         user_name         user_location  ...               source is_retweet\n",
              "0           ·èâ·é•‚òª’¨ÍÇÖœÆ            astroworld  ...   Twitter for iPhone      False\n",
              "1    Tom Basile üá∫üá∏          New York, NY  ...  Twitter for Android      False\n",
              "2  Time4fisticuffs      Pewee Valley, KY  ...  Twitter for Android      False\n",
              "3      ethel mertz  Stuck in the Middle   ...   Twitter for iPhone      False\n",
              "4         DIPR-J&K     Jammu and Kashmir  ...  Twitter for Android      False\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install neattext\n",
        "# Load Text Cleaning Package\n",
        "import neattext.functions as nfx"
      ],
      "metadata": {
        "id": "vvR8I2uDKAy1",
        "outputId": "ac7c871a-52da-4153-f8ac-c1a0b617be1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting neattext\n",
            "  Downloading neattext-0.1.2-py3-none-any.whl (114 kB)\n",
            "\u001b[?25l\r\u001b[K     |‚ñà‚ñà‚ñâ                             | 10 kB 17.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                          | 20 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                       | 30 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                    | 40 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                 | 51 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè              | 61 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà            | 71 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà         | 81 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ      | 92 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 102 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 112 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 114 kB 5.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: neattext\n",
            "Successfully installed neattext-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cleaning Text\n",
        "df['clean_tweet'] = df['text'].apply(nfx.remove_hashtags)\n",
        "df['clean_tweet'] = df['clean_tweet'].apply(lambda x: nfx.remove_userhandles(x))\n",
        "# Cleaning Text: Multiple WhiteSpaces\n",
        "df['clean_tweet'] = df['clean_tweet'].apply(nfx.remove_multiple_spaces)\n",
        "# Cleaning Text : Remove urls\n",
        "df['clean_tweet'] = df['clean_tweet'].apply(nfx.remove_urls)\n",
        "# Cleaning Text: Punctuations\n",
        "df['clean_tweet'] = df['clean_tweet'].apply(nfx.remove_puncts)\n",
        "#Remove blank rows if any.\n",
        "df['clean_tweet'] .dropna(inplace=True)\n",
        "# Change all the text to lower case.\n",
        "df['clean_tweet']  = [entry.lower() for entry in df['clean_tweet'] ]\n",
        "df[['text','clean_tweet']]"
      ],
      "metadata": {
        "id": "duT9A0NOKmC_",
        "outputId": "0e6a8517-2172-49a8-a562-78bb732fe060",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-fbb5ae78-7ce2-45de-b5f2-d14fb3c379d4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>clean_tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>If I smelled the scent of hand sanitizers toda...</td>\n",
              "      <td>if i smelled the scent of hand sanitizers toda...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hey @Yankees @YankeesPR and @MLB - wouldn't it...</td>\n",
              "      <td>hey and  wouldnt it have made more sense to ha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@diane3443 @wdunlap @realDonaldTrump Trump nev...</td>\n",
              "      <td>trump never once claimed was a hoax we all cl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@brookbanktv The one gift #COVID19 has give me...</td>\n",
              "      <td>the one gift has give me is an appreciation f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>25 July : Media Bulletin on Novel #CoronaVirus...</td>\n",
              "      <td>25 july : media bulletin on novel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>179103</th>\n",
              "      <td>Thanks @IamOhmai for nominating me for the @WH...</td>\n",
              "      <td>thanks for nominating me for the challenge i n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>179104</th>\n",
              "      <td>2020! The year of insanity! Lol! #COVID19 http...</td>\n",
              "      <td>2020 the year of insanity lol</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>179105</th>\n",
              "      <td>@CTVNews A powerful painting by Juan Lucena. I...</td>\n",
              "      <td>a powerful painting by juan lucena its a trib...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>179106</th>\n",
              "      <td>More than 1,200 students test positive for #CO...</td>\n",
              "      <td>more than 1200 students test positive for at m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>179107</th>\n",
              "      <td>I stop when I see a Stop\\n\\n@SABCNews\\n@Izinda...</td>\n",
              "      <td>i stop when i see a stop</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>179108 rows √ó 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fbb5ae78-7ce2-45de-b5f2-d14fb3c379d4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fbb5ae78-7ce2-45de-b5f2-d14fb3c379d4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fbb5ae78-7ce2-45de-b5f2-d14fb3c379d4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                     text                                        clean_tweet\n",
              "0       If I smelled the scent of hand sanitizers toda...  if i smelled the scent of hand sanitizers toda...\n",
              "1       Hey @Yankees @YankeesPR and @MLB - wouldn't it...  hey and  wouldnt it have made more sense to ha...\n",
              "2       @diane3443 @wdunlap @realDonaldTrump Trump nev...   trump never once claimed was a hoax we all cl...\n",
              "3       @brookbanktv The one gift #COVID19 has give me...   the one gift has give me is an appreciation f...\n",
              "4       25 July : Media Bulletin on Novel #CoronaVirus...                 25 july : media bulletin on novel \n",
              "...                                                   ...                                                ...\n",
              "179103  Thanks @IamOhmai for nominating me for the @WH...  thanks for nominating me for the challenge i n...\n",
              "179104  2020! The year of insanity! Lol! #COVID19 http...                     2020 the year of insanity lol \n",
              "179105  @CTVNews A powerful painting by Juan Lucena. I...   a powerful painting by juan lucena its a trib...\n",
              "179106  More than 1,200 students test positive for #CO...  more than 1200 students test positive for at m...\n",
              "179107  I stop when I see a Stop\\n\\n@SABCNews\\n@Izinda...                          i stop when i see a stop \n",
              "\n",
              "[179108 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization : In this each entry in the corpus will be broken into set of words\n",
        "df['clean_tweet']= [word_tokenize(entry) for entry in df['clean_tweet']]\n",
        "# Step - d : Remove Stop words, Non-Numeric and perfom Word Stemming/Lemmenting.\n"
      ],
      "metadata": {
        "id": "YxiL2FPtu_-Y"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['clean_tweet']"
      ],
      "metadata": {
        "id": "JAnxW9vBwSG8",
        "outputId": "6c96fdea-ef49-4ede-aec7-f385706e05b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         [if, i, smelled, the, scent, of, hand, sanitiz...\n",
              "1         [hey, and, wouldnt, it, have, made, more, sens...\n",
              "2         [trump, never, once, claimed, was, a, hoax, we...\n",
              "3         [the, one, gift, has, give, me, is, an, apprec...\n",
              "4                 [25, july, :, media, bulletin, on, novel]\n",
              "                                ...                        \n",
              "179103    [thanks, for, nominating, me, for, the, challe...\n",
              "179104                 [2020, the, year, of, insanity, lol]\n",
              "179105    [a, powerful, painting, by, juan, lucena, its,...\n",
              "179106    [more, than, 1200, students, test, positive, f...\n",
              "179107                     [i, stop, when, i, see, a, stop]\n",
              "Name: clean_tweet, Length: 179108, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# WordNetLemmatizer requires Pos tags to understand if the word is noun or verb or adjective etc. By default it is set to Noun\n",
        "tag_map = defaultdict(lambda : wn.NOUN)\n",
        "tag_map['J'] = wn.ADJ\n",
        "tag_map['V'] = wn.VERB\n",
        "tag_map['R'] = wn.ADV\n",
        "for index,entry in enumerate(df['clean_tweet']):\n",
        "    # Declaring Empty List to store the words that follow the rules for this step\n",
        "    Final_words = []\n",
        "    # Initializing WordNetLemmatizer()\n",
        "    word_Lemmatized = WordNetLemmatizer()\n",
        "    # pos_tag function below will provide the 'tag' i.e if the word is Noun(N) or Verb(V) or something else.\n",
        "    for word, tag in pos_tag(entry):\n",
        "        # Below condition is to check for Stop words and consider only alphabets\n",
        "        if word not in stopwords.words('english') and word.isalpha():\n",
        "            word_Final = word_Lemmatized.lemmatize(word,tag_map[tag[0]])\n",
        "            Final_words.append(word_Final)\n",
        "    # The final processed set of words for each iteration will be stored in 'text_final'\n",
        "    df.loc[index,'clean_textt'] = str(Final_words)\n"
      ],
      "metadata": {
        "id": "wR3_JB8dwPBO",
        "outputId": "c80488a8-aabb-4244-8309-4359c41c5503",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-b3ab67821c91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# Below condition is to check for Stop words and consider only alphabets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misalpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0mword_Final\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_Lemmatized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtag_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mFinal_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_Final\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/corpus/reader/wordlist.py\u001b[0m in \u001b[0;36mwords\u001b[0;34m(self, fileids, ignore_lines_startswith)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \"\"\"\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_lines_startswith\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         return [line for line in line_tokenize(self.raw(fileids))\n\u001b[0m\u001b[1;32m     23\u001b[0m                 if not line.startswith(ignore_lines_startswith)]\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/corpus/reader/wordlist.py\u001b[0m in \u001b[0;36mraw\u001b[0;34m(self, fileids)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfileids\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfileids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fileids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfileids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfileids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfileids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/corpus/reader/wordlist.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfileids\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfileids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fileids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfileids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfileids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfileids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sentiment(text):\n",
        "    blob = TextBlob(text)\n",
        "    sentiment_polarity = blob.sentiment.polarity\n",
        "    sentiment_subjectivity = blob.sentiment.subjectivity\n",
        "    if sentiment_polarity > 0:\n",
        "        sentiment_label = 'Positive'\n",
        "    elif sentiment_polarity < 0:\n",
        "        sentiment_label = 'Negative'\n",
        "    else:\n",
        "        sentiment_label = 'Neutral'\n",
        "    result = {'polarity':sentiment_polarity,\n",
        "              'subjectivity':sentiment_subjectivity,\n",
        "              'sentiment':sentiment_label}\n",
        "    return result"
      ],
      "metadata": {
        "id": "wJB6z7xlKmEP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y=df['Sentiment'].values\n",
        "y.shape"
      ],
      "metadata": {
        "id": "kdhQR-vky7-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=df['clean_textt'].values\n",
        "x.shape"
      ],
      "metadata": {
        "id": "cTHXrn3xy_Ez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "(x_train,x_test,y_train,y_test)=train_test_split(x,y,test_size=0.4)\n",
        "x_train.shape\n",
        "y_train.shape\n",
        "x_test.shape\n",
        "y_test.shape"
      ],
      "metadata": {
        "id": "jwqFzaHDzQnk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1=pd.DataFrame(x_train)\n",
        "df1=df1.rename(columns={0:'clean_textt'})\n",
        "df2=pd.DataFrame(y_train)\n",
        "df2=df2.rename(columns={0:'sentiment'})\n",
        "df_train=pd.concat([df1,df2],axis=1)\n",
        "df_train.head()"
      ],
      "metadata": {
        "id": "RpyiatEuzbet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df3=pd.DataFrame(x_test)\n",
        "df3=df3.rename(columns={0:'clean_textt'})\n",
        "df4=pd.DataFrame(y_test)\n",
        "df4=df2.rename(columns={0:'sentiment'})\n",
        "df_test=pd.concat([df3,df4],axis=1)\n",
        "df_test.head()"
      ],
      "metadata": {
        "id": "h4alswlwznIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Text\n",
        "ex1 = df['clean_tweet'].iloc[0]\n",
        "df['sentiment_results'] = df['clean_tweet'].apply(get_sentiment)\n",
        "df['sentiment_results']\n"
      ],
      "metadata": {
        "id": "kw1cv4HfMWCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.join(pd.json_normalize(df['sentiment_results']))\n",
        "df.head()"
      ],
      "metadata": {
        "id": "BIUsnSR5NX8b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}